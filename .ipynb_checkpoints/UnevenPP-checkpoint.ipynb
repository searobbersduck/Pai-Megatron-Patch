{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ee1bf1",
   "metadata": {},
   "source": [
    "## Uneven pp\n",
    "\n",
    "### args:\n",
    "\n",
    "```\n",
    "        --tensor-model-parallel-size ${TP} \\\n",
    "        --pipeline-model-parallel-size ${PP} \\\n",
    "        --decoder-first-pipeline-num-layers ${FIRST_PP_LAYERS} \\\n",
    "        --decoder-last-pipeline-num-layers ${LAST_PP_LAYERS} \\\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e77e4",
   "metadata": {},
   "source": [
    "REF: [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473)\n",
    "\n",
    "![image.png](./images/pp_1f1b.png)\n",
    "\n",
    "We denote the number of microbatches in a batch as $m$, the number of pipeline stages (number of devices used for pipeline parallelism) as $p$, the ideal time per iteration as $t_{id}$ (assuming perfect or ideal scaling), and the time to execute a single microbatchâ€™s forward and backward pass as $t_{f}$ and $t_{b}$. In this schedule, the pipeline bubble consists of $p - 1$ forward passes at the start of a batch, and $p - 1$ backward passes at the end. The total amount of time spent in the The pipeline bubble is then $t_{pb} = (p - 1)\\cdot(t_{f}+t_{b})$. The ideal processing time for the batch is $t_{id} = m\\cdot(t_{f} + t_{b})$. Therefore, the fraction of ideal computation time spent in the pipeline bubble is:\n",
    "\n",
    "$$\\text{Bubble time fraction (pipeline bubble size)} =  \\frac{t_{pb}}{t_{id}}=\\frac{p - 1}{m}$$ \n",
    "\n",
    "<br>\n",
    "\n",
    "Ideally, the forward and reverse times on each pipeline rank are as balanced as possible, and the bubble time can be minimized. We can take a more intuitive look at the bubble from the following figure:\n",
    "\n",
    "![image-2.png](./images/pp_GPipe.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's analyze the situation of unbalanced Pipeline Parallelism (PP):\n",
    "\n",
    "![image-2.png](./images/pp_uneven_GPipe.png)\n",
    "\n",
    "\n",
    "\n",
    "![image-2.png](./images/pp_vs_uneven_pp_additional_bubbles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e57607",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>\n",
    "## TFLOPS Calculation\n",
    "\n",
    "### ViT Encoder TFLOPS\n",
    "\n",
    "Formula for the number of floating-point operations (FLOPS) in the convolutional part (forward pass) of the Vision Transformer (ViT):\n",
    "\n",
    "$\\text{FLOPS}_{\\text{conv_forward}} = 2Nhcp^{2}$\n",
    "\n",
    " \n",
    "<br>\n",
    "Where:\n",
    "\n",
    "$h$ : Hidden size\n",
    "\n",
    "$p$ : Patch size\n",
    "\n",
    "$c$ : Image input channels\n",
    "\n",
    "$N$ : Number of image tokens after patchification\n",
    "\n",
    "$l$ : Number of transformer layers\n",
    "\n",
    "\n",
    "Formula for the number of image tokens after patchification:\n",
    "\n",
    "$N = \\left\\lfloor\\frac{W + p - 1}{p}\\right\\rfloor\\times\\left\\lfloor\\frac{H + p - 1}{p}\\right\\rfloor$\n",
    "\n",
    "\n",
    "Formula for the number of floating-point operations (FLOPS) in the Transformer part (forward pass):\n",
    "\n",
    "$\\text{FLOPS}_{\\text{transformer_forward}} = (24Nh^{2}+4hN^{2})l$\n",
    "\n",
    "\n",
    "Formula for the total trillion floating-point operations per second (TFLOPS) of the ViT (forward pass + backward pass) (Note: The classifier head is ignored):\n",
    "\n",
    "$\\text{FLOPS}_{\\text{ViT_(forward+backward)}} = 3\\times((24Nh^{2}+4hN^{2})L + 2Nhcp^{2})$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### LLM TFLOPS\n",
    "\n",
    "In most case: $h_2=4h$\n",
    "\n",
    "$\\text{FLOPS}_{\\text{LLM_(forward+backward)}} = 3\\times(24Nh^{2}+4hN^{2})L$\n",
    "\n",
    "$\\text{FLOPS}_{\\text{one_layer_forward}} = 24Nh^{2}+4hN^{2}$\n",
    "\n",
    "If $h_2\\ne4h$:\n",
    "\n",
    "$\\text{FLOPS}_{\\text{one_layer_forward}} = 8Nh^{2}+4hN^{2}+4Nhh_2$\n",
    "\n",
    "$\\text{FLOPS}_{\\text{one_layer_forward_backward}} = 3\\times(8Nh^{2}+4hN^{2}+4Nhh_2)$\n",
    "\n",
    "$\\text{FLOPS}_{\\text{llm_forward_backward}} = 3\\times(8Nh^{2}+4hN^{2}+4Nhh_2)L$\n",
    "\n",
    "Where:\n",
    "\n",
    "$h$ : Hidden size\n",
    "\n",
    "$h_2$ : FFN immediate size\n",
    "\n",
    "$N$ : Sequence length includes images tokens and text tokens\n",
    "\n",
    "$l$ : Number of transformer layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e646f7",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Uneven pp parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a06584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "vit_tflops: 8.75254775808\n",
      "llm_tflops: 33.462090203136\n",
      "llm_tflops_onelayer: 1.195074650112\n",
      "nlayers_per_rank:\t 17.66192511792453\n"
     ]
    }
   ],
   "source": [
    "def vit_encoder_tflops_calculator(W,H,P,hidden_size, in_channels, L):\n",
    "    N = ((W+P-1)//P) * ((H+P-1)//P)\n",
    "    print(N)\n",
    "    tflops_conv_forward = 2*N*hidden_size*in_channels*(P**2)\n",
    "    tflops_transformer_forward = (24*N*(hidden_size**2) + 4*hidden_size*(N**2))*L\n",
    "    tflops=3*(tflops_conv_forward + tflops_transformer_forward)\n",
    "    return tflops/1e12\n",
    "    \n",
    "W=224\n",
    "H=224\n",
    "P=14\n",
    "hidden_size=4096\n",
    "in_channels=3\n",
    "L=28\n",
    "\n",
    "vit_tflops=vit_encoder_tflops_calculator(W,H,P, hidden_size, in_channels, L)\n",
    "print(\"vit_tflops:\", vit_tflops)\n",
    "\n",
    "\n",
    "def llm_encoder_tflops_calculator(hidden_size, L, seq_len, intermediate_size=None):\n",
    "    if intermediate_size is None:\n",
    "        tflops_one_transformer_layer_forward=24*seq_len*(hidden_size**2) + 4*hidden_size*(seq_len**2)\n",
    "    else:\n",
    "        tflops_one_transformer_layer_forward=8*seq_len*(hidden_size**2) + 4*hidden_size*(seq_len**2) + 4*seq_len*hidden_size*intermediate_size\n",
    "#     tflops_transformer_forward = (24*seq_len*(hidden_size**2) + 4*hidden_size*(seq_len**2))*L\n",
    "    tflops_transformer_forward = tflops_one_transformer_layer_forward * L\n",
    "    tflops = tflops_transformer_forward*3/1e12\n",
    "    tflops_one_layer = tflops_one_transformer_layer_forward*3/1e12\n",
    "    return tflops, tflops_one_layer\n",
    "\n",
    "hidden_size=3584\n",
    "intermediate_size=18944\n",
    "seq_len=1024\n",
    "L=28\n",
    "\n",
    "llm_tflops, llm_tflops_onelayer=llm_encoder_tflops_calculator(hidden_size, L, seq_len,intermediate_size)\n",
    "print('llm_tflops:', llm_tflops)\n",
    "print('llm_tflops_onelayer:', llm_tflops_onelayer)\n",
    "\n",
    "nGPUs=2\n",
    "\n",
    "total_tflops = (vit_tflops+llm_tflops)\n",
    "nlayers_per_rank = total_tflops/nGPUs/llm_tflops_onelayer\n",
    "print(\"nlayers_per_rank:\\t\", nlayers_per_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6249d",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## GPU Memory Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c88f82",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## How to config Uneven PP parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f6a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
